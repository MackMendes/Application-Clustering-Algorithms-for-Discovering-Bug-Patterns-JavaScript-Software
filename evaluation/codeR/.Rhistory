tamanhos_Larguras = datasetIris[,-5]
# Executar o algoritmo k-means com o dataset filtrado acima (x) e pedindo para encontrar 3 grupos (centers).
resultado <- kmeans(x = tamanhos_Larguras, centers = 3)
# monstrar o resultado
resultado
# Unindo os resultados com os nomes das espécies
table(datasetIris$Especies, resultado$cluster)
# Plotar o resultado, levando em consideração os atributos da Sépala
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster)
points(resultado$centers[,c("Sepala.Tamanho", "Sepala.Largura")], col=1:3, pch="o", cex=3)
## Exemplo, Aprendizado de Máquina não supervisinado
# Carregamento em memório a biblioteca com os algoritmos de SVM
library("e1071")
# Obtendo o dataset com espécies da flor Iris
datasetIris <- iris
names(datasetIris) <- c("Sepala.Tamanho", "Sepala.Largura", "Petala.Tamanho", "Petala.Largura", "Especies")
# Vamos verificar como esta a distribuição deste dataset
summary(datasetIris)
datasetIrisPart  <- datasetIris[,c(3,4,5)]
summary(datasetIrisPart)
# Desta vez, preciso mostrar um pouco do Dataset para o meu algoritmo e ele tem que aprender.
# Depois, tenho que testa-lo com o resto do dataset
indexes = sample(1:nrow(datasetIrisPart), size=(0.3*nrow(datasetIrisPart)))
#################################
# Cortar o dataset aleatoriamente
dataset_treino = datasetIrisPart[-indexes,]
dataset_teste = datasetIrisPart[indexes,]
# Mostrar dataset de teste
summary(dataset_teste)
# Mostrar dataset de treino
summary(dataset_treino)
attach(dataset_treino)
####
# Vou treinar o meu modelo SVM!
svm_model <- svm(Especies ~ ., data = dataset_treino)
####
#svm_model <- svm(Especies ~ ., data=dataset_treino, kernel="radial", cost=1, gamma=1)
#Plot the results
plot(svm_model , dataset_treino)
# Pegando apenas as colunas com os tamanhos e larguras (da Sépala e da Pétala) - chamado de X
tamanhos_Larguras_teste = subset(dataset_teste, select = -Especies)
summary(tamanhos_Larguras_teste)
####
# Agora, vou pegar o Dataset de Teste, sem os rótulos das Espécies
svm_predicao <- predict(svm_model, newdata = tamanhos_Larguras_teste)
####
# Agora, vamos verificar os acertos da Predição feita acima, passando apenas os rótulos com as Espécies
table(dataset_teste[,3], svm_predicao)
# Mostrar dataset de teste, novamente
summary(dataset_teste)
# Calculando a acurácia
sum(diag(table(dataset_teste[,3], svm_predicao))) / length(dataset_teste[,3])
plot(svm_model, dataset_teste)
## Exemplo, Aprendizado de Máquina não supervisinado
# Obtendo o dataset com espécies da flor Iris
datasetIris <- iris
names(datasetIris) <- c("Sepala.Tamanho", "Sepala.Largura", "Petala.Tamanho", "Petala.Largura", "Especies")
# Vamos verificar como esta a distribuição deste dataset
summary(datasetIris)
# Pegando apenas as colunas com os tamanhos e larguras (da Sépala e da Pétala)
tamanhos_Larguras = datasetIris[,-5]
# Executar o algoritmo k-means com o dataset filtrado acima (x) e pedindo para encontrar 3 grupos (centers).
resultado <- kmeans(x = tamanhos_Larguras, centers = 3)
# monstrar o resultado
resultado
# Unindo os resultados com os nomes das espécies
table(datasetIris$Especies, resultado$cluster)
# Plotar o resultado, levando em consideração os atributos da Sépala
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster)
points(resultado$centers[,c("Sepala.Tamanho", "Sepala.Largura")], col=1:3, pch="o", cex=3)
## Exemplo, Aprendizado de Máquina não supervisinado
# Carregamento em memório a biblioteca da Rede Neural
library(nnet)
# Obtendo o dataset com espécies da flor Iris
datasetIris <- iris
names(datasetIris) <- c("Sepala.Tamanho", "Sepala.Largura", "Petala.Tamanho", "Petala.Largura", "Especies")
# Vamos verificar como esta a distribuição deste dataset
summary(datasetIris)
# Desta vez, preciso mostrar um pouco do Dataset para o meu algoritmo e ele tem que aprender.
# Depois, tenho que testa-lo com o resto do dataset
xEntrada <- data.frame(datasetIris$Sepala.Tamanho, datasetIris$Sepala.Largura, datasetIris$Petala.Tamanho,
datasetIris$Petala.Largura)
xSaida <- data.frame(setosa = ifelse(datasetIris$Especies == "setosa",1,0),
versicolor = ifelse(datasetIris$Especies == "versicolor",1,0),
virginica = ifelse(datasetIris$Especies == "virginica",1,0))
summary(xEntrada)
summary(xSaida)
indexes = sample(1:nrow(datasetIris), size=(0.3*nrow(datasetIris)))
#################################
# Cortar o dataset aleatoriamente
dataset_treino_Entrada = xEntrada[-indexes,]
dataset_teste_Entrada = xEntrada[indexes,]
# Cortar o dataset aleatoriamente
dataset_treino_Saida = xSaida[-indexes,]
dataset_teste_Saida = xSaida[indexes,]
####
# Vou treinar a minha rede neural
# Size = Tamanho da camada escondida;
# rang = Pesos aleatórios iniciais em [-rang, rang];
# Decay = Parâmetro para a deterioração de peso;
# maxit = Máximo número de interações até convergi;
rna_model <- nnet(dataset_treino_Entrada, dataset_treino_Saida, size = 2, rang = 0.1,
decay = 5e-4, maxit = 1000)
####
library(NeuralNetTools)
plotnet(rna_model, alpha=0.6)
####
# Agora, vou pegar o Dataset de Teste, sem os rótulos das Espécies
rna_predicao <- round(predict(rna_model, dataset_teste_Entrada))
####
Table1<-abs(rna_predicao - dataset_teste_Saida)
Error <- (sum(Table1)/2) / nrow(dataset_teste_Saida)
# Calculando acurácia
1-Error
#Plot the results
plot(dataset_treino_Entrada, rna_model$fitted.values)
## Exemplo, Aprendizado de Máquina não supervisinado
# Carregamento em memório a biblioteca da Rede Neural
library(nnet)
# Obtendo o dataset com espécies da flor Iris
datasetIris <- iris
names(datasetIris) <- c("Sepala.Tamanho", "Sepala.Largura", "Petala.Tamanho", "Petala.Largura", "Especies")
# Vamos verificar como esta a distribuição deste dataset
summary(datasetIris)
# Desta vez, preciso mostrar um pouco do Dataset para o meu algoritmo e ele tem que aprender.
# Depois, tenho que testa-lo com o resto do dataset
xEntrada <- data.frame(datasetIris$Sepala.Tamanho, datasetIris$Sepala.Largura, datasetIris$Petala.Tamanho,
datasetIris$Petala.Largura)
xSaida <- data.frame(setosa = ifelse(datasetIris$Especies == "setosa",1,0),
versicolor = ifelse(datasetIris$Especies == "versicolor",1,0),
virginica = ifelse(datasetIris$Especies == "virginica",1,0))
summary(xEntrada)
summary(xSaida)
indexes = sample(1:nrow(datasetIris), size=(0.3*nrow(datasetIris)))
#################################
# Cortar o dataset aleatoriamente
dataset_treino_Entrada = xEntrada[-indexes,]
dataset_teste_Entrada = xEntrada[indexes,]
# Cortar o dataset aleatoriamente
dataset_treino_Saida = xSaida[-indexes,]
dataset_teste_Saida = xSaida[indexes,]
####
# Vou treinar a minha rede neural
# Size = Tamanho da camada escondida;
# rang = Pesos aleatórios iniciais em [-rang, rang];
# Decay = Parâmetro para a deterioração de peso;
# maxit = Máximo número de interações até convergi;
rna_model <- nnet(dataset_treino_Entrada, dataset_treino_Saida, size = 2, rang = 0.1,
decay = 5e-4, maxit = 1000)
####
library(NeuralNetTools)
plotnet(rna_model, alpha=0.6)
####
# Agora, vou pegar o Dataset de Teste, sem os rótulos das Espécies
rna_predicao <- round(predict(rna_model, dataset_teste_Entrada))
####
Table1<-abs(rna_predicao - dataset_teste_Saida)
Error <- (sum(Table1)/2) / nrow(dataset_teste_Saida)
# Calculando acurácia
1-Error
#Plot the results
#plot(dataset_treino_Entrada, rna_model$fitted.values)
View(datasetIris)
## Exemplo, Aprendizado de Máquina não supervisinado
# Obtendo o dataset com espécies da flor Iris
datasetIris <- iris
names(datasetIris) <- c("Sepala.Tamanho", "Sepala.Largura", "Petala.Tamanho", "Petala.Largura", "Especies")
# Vamos verificar como esta a distribuição deste dataset
summary(datasetIris)
# Pegando apenas as colunas com os tamanhos e larguras (da Sépala e da Pétala)
tamanhos_Larguras = datasetIris[,-5]
# Executar o algoritmo k-means com o dataset filtrado acima (x) e pedindo para encontrar 3 grupos (centers).
resultado <- kmeans(x = tamanhos_Larguras, centers = 3)
# monstrar o resultado
resultado
# Unindo os resultados com os nomes das espécies
table(datasetIris$Especies, resultado$cluster)
# Plotar o resultado, levando em consideração os atributos da Sépala
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster)
points(resultado$centers[,c("Sepala.Tamanho", "Sepala.Largura")], col=1:3, pch="o", cex=3)
## Exemplo, Aprendizado de Máquina não supervisinado
# Carregamento em memório a biblioteca da Rede Neural
library(nnet)
# Obtendo o dataset com espécies da flor Iris
datasetIris <- iris
names(datasetIris) <- c("Sepala.Tamanho", "Sepala.Largura", "Petala.Tamanho", "Petala.Largura", "Especies")
# Vamos verificar como esta a distribuição deste dataset
summary(datasetIris)
# Desta vez, preciso mostrar um pouco do Dataset para o meu algoritmo e ele tem que aprender.
# Depois, tenho que testa-lo com o resto do dataset
xEntrada <- data.frame(datasetIris$Sepala.Tamanho, datasetIris$Sepala.Largura, datasetIris$Petala.Tamanho,
datasetIris$Petala.Largura)
xSaida <- data.frame(setosa = ifelse(datasetIris$Especies == "setosa",1,0),
versicolor = ifelse(datasetIris$Especies == "versicolor",1,0),
virginica = ifelse(datasetIris$Especies == "virginica",1,0))
summary(xEntrada)
summary(xSaida)
indexes = sample(1:nrow(datasetIris), size=(0.3*nrow(datasetIris)))
#################################
# Cortar o dataset aleatoriamente
dataset_treino_Entrada = xEntrada[-indexes,]
dataset_teste_Entrada = xEntrada[indexes,]
# Cortar o dataset aleatoriamente
dataset_treino_Saida = xSaida[-indexes,]
dataset_teste_Saida = xSaida[indexes,]
####
# Vou treinar a minha rede neural
# Size = Tamanho da camada escondida;
# rang = Pesos aleatórios iniciais em [-rang, rang];
# Decay = Parâmetro para a deterioração de peso;
# maxit = Máximo número de interações até convergi;
rna_model <- nnet(dataset_treino_Entrada, dataset_treino_Saida, size = 2, rang = 0.1,
decay = 5e-4, maxit = 1000)
####
library(NeuralNetTools)
plotnet(rna_model, alpha=0.6)
####
# Agora, vou pegar o Dataset de Teste, sem os rótulos das Espécies
rna_predicao <- round(predict(rna_model, dataset_teste_Entrada))
####
Table1<-abs(rna_predicao - dataset_teste_Saida)
Error <- (sum(Table1)/2) / nrow(dataset_teste_Saida)
# Calculando acurácia
1-Error
#Plot the results
#plot(dataset_treino_Entrada, rna_model$fitted.values)
## Exemplo, Aprendizado de Máquina não supervisinado
# Carregamento em memório a biblioteca com os algoritmos de SVM
library("e1071")
# Obtendo o dataset com espécies da flor Iris
datasetIris <- iris
names(datasetIris) <- c("Sepala.Tamanho", "Sepala.Largura", "Petala.Tamanho", "Petala.Largura", "Especies")
# Vamos verificar como esta a distribuição deste dataset
summary(datasetIris)
datasetIrisPart  <- datasetIris[,c(3,4,5)]
summary(datasetIrisPart)
# Desta vez, preciso mostrar um pouco do Dataset para o meu algoritmo e ele tem que aprender.
# Depois, tenho que testa-lo com o resto do dataset
indexes = sample(1:nrow(datasetIrisPart), size=(0.3*nrow(datasetIrisPart)))
#################################
# Cortar o dataset aleatoriamente
dataset_treino = datasetIrisPart[-indexes,]
dataset_teste = datasetIrisPart[indexes,]
# Mostrar dataset de teste
summary(dataset_teste)
# Mostrar dataset de treino
summary(dataset_treino)
attach(dataset_treino)
####
# Vou treinar o meu modelo SVM!
svm_model <- svm(Especies ~ ., data = dataset_treino)
####
#svm_model <- svm(Especies ~ ., data=dataset_treino, kernel="radial", cost=1, gamma=1)
#Plot the results
plot(svm_model , dataset_treino)
# Pegando apenas as colunas com os tamanhos e larguras (da Sépala e da Pétala) - chamado de X
tamanhos_Larguras_teste = subset(dataset_teste, select = -Especies)
summary(tamanhos_Larguras_teste)
####
# Agora, vou pegar o Dataset de Teste, sem os rótulos das Espécies
svm_predicao <- predict(svm_model, newdata = tamanhos_Larguras_teste)
####
# Agora, vamos verificar os acertos da Predição feita acima, passando apenas os rótulos com as Espécies
table(dataset_teste[,3], svm_predicao)
# Mostrar dataset de teste, novamente
summary(dataset_teste)
# Calculando a acurácia
sum(diag(table(dataset_teste[,3], svm_predicao))) / length(dataset_teste[,3])
plot(svm_model, dataset_teste)
dataset.math <- read.csv("G:/Mestrado/Meus experimentos/BugAID-Modificado/Meus Resultados/7 - Depois de Modificado/dataset-math.csv", header=FALSE, sep=";")
View(dataset.math)
dataset.math[is.null(dataset.math)] <- ''
View(dataset.math)
dataset.math[is.na(dataset.math)] <- ''
dataset.math[is.na(dataset.math)] <- ""
dataset.math[is.na(dataset.math$V10)] <- ""
dataset.math[is.v(dataset.math$V10)] <- ""
dataset.math[is.null(dataset.math$V10)] <- ""
dataset.math[dataset.math == NULL] <- ""
dataset.math[dataset.math == "NULL"] <- ""
dataset.math[dataset.math == 'NULL'] <- ""
dataset.math[dataset.math == "NULL"] <- ""
dataset.math[dataset.math == "NULL"] <- ""
View(dataset.math)
write.csv(x = dataset.math, file="results/dataset-math-clear.csv")
write.csv(x = dataset.math, file="dataset-math-clear.csv")
View(dataset.math)
library(cluster)
library(HSAUR)
data(pottery)
km    <- kmeans(pottery,3)
dissE <- daisy(pottery)
dE2   <- dissE^2
sk2   <- silhouette(km$cl, dE2)
plot(sk2)
install.packages(HSAUR)
install.packages('HSAUR')
library(cluster)
library(HSAUR)
data(pottery)
km    <- kmeans(pottery,3)
dissE <- daisy(pottery)
dE2   <- dissE^2
sk2   <- silhouette(km$cl, dE2)
plot(sk2)
plot(pottery)
library(cluster)
library(fpc)
data(iris)
dat <- iris[, -5] # without known classification
# Kmeans clustre analysis
clus <- kmeans(dat, centers=3)
install.packages("fpc")
plotcluster(dat, clus$cluster)
library(fpc)
plotcluster(dat, clus$cluster)
library("dbscan")
data("moons")
plot(moons, pch=20)
cl <- hdbscan(moons, minPts = 5)
plot(moons, col=cl$cluster+1, pch=20)
?plot
plot.hdbscan
?plot.hdbscan
?plot
plot(moons, col=cl$cluster+1, pch=20, xlab="Teste")
plotcluster(dat, clus$cluster)
clusplot(dat, clus$cluster, color=TRUE, shade=TRUE,
labels=2, lines=0)
plot(moons, col=cl$cluster+1, pch=20)
clusplot(moons, cl$cluster+1, color=TRUE, shade=TRUE,
+          labels=2, lines=0)
clusplot(moons, cl$cluster+1, color=TRUE, shade=TRUE, labels=2, lines=0)
clusplot(moons, cl$cluster+1, color=TRUE, shade=FALSE, labels=2, lines=0)
clusplot(moons, cl$cluster+1, color=TRUE, shade=FALSE, labels=1, lines=0)
data("moons")
library(fpc)
data("moons")
plot(moons, pch=20)
plot(moons, pch=20)
plot(sk2)
data("moons")
data(moons)
library("dbscan")
data("moons")
plot(moons, pch=20)
cl <- hdbscan(moons, minPts = 5)
eclust
??eclust
library(fpc)
plotcluster(moons, cl$cluster)
library("dbscan")
data("moons")
plot(moons, pch=20)
clusplot(moons, cl$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
plotcluster(moons, cl$cluster)
clusplot(moons, cl$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
clusplot(moons, cl$cluster, color=TRUE, shade=FALSE, labels=2, lines=0)
library(cluster)
clusplot(moons, cl$cluster, color=TRUE, shade=FALSE, labels=2, lines=0)
clusplot(moons, cl$cluster, color=TRUE, shade=FALSE, labels=0, lines=0)
plot(moons, col=cl$cluster+1, pch=20)
clusplot(moons, cl$cluster, color=TRUE, shade=FALSE, labels=0, lines=0)
clusplot(moons, cl$cluster, color=FALSE, shade=FALSE, labels=0, lines=0)
clusplot(moons, cl$cluster, color=FALSE, shade=FALSE, labels=3, lines=0)
clusplot(moons, cl$cluster, color=FALSE, shade=FALSE, labels=1, lines=0)
## Exemplo, Aprendizado de Máquina não supervisinado
# Obtendo o dataset com espécies da flor Iris
datasetIris <- iris
names(datasetIris) <- c("Sepala.Tamanho", "Sepala.Largura", "Petala.Tamanho", "Petala.Largura", "Especies")
# Vamos verificar como esta a distribuição deste dataset
summary(datasetIris)
# Pegando apenas as colunas com os tamanhos e larguras (da Sépala e da Pétala)
tamanhos_Larguras = datasetIris[,-5]
# Executar o algoritmo k-means com o dataset filtrado acima (x) e pedindo para encontrar 3 grupos (centers).
resultado <- kmeans(x = tamanhos_Larguras, centers = 3)
# monstrar o resultado
resultado
# Unindo os resultados com os nomes das espécies
table(datasetIris$Especies, resultado$cluster)
# Plotar o resultado, levando em consideração os atributos da Sépala
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster)
points(resultado$centers[,c("Sepala.Tamanho", "Sepala.Largura")], col=1:3, pch="o", cex=3)
library("dbscan")
data("moons")
resultado <- kmeans(x = moons, centers = 3)
plot(moons, col=resultado$cluster)
resultado <- kmeans(x = moons, centers = 3)
plot(moons, col=resultado$cluster)
resultado <- kmeans(x = moons, centers = 3)
plot(moons, col=resultado$cluster)
## Exemplo, Aprendizado de Máquina não supervisinado
# Obtendo o dataset com espécies da flor Iris
datasetIris <- iris
names(datasetIris) <- c("Sepala.Tamanho", "Sepala.Largura", "Petala.Tamanho", "Petala.Largura", "Especies")
# Vamos verificar como esta a distribuição deste dataset
summary(datasetIris)
# Pegando apenas as colunas com os tamanhos e larguras (da Sépala e da Pétala)
tamanhos_Larguras = datasetIris[,-5]
# Executar o algoritmo k-means com o dataset filtrado acima (x) e pedindo para encontrar 3 grupos (centers).
resultado <- kmeans(x = tamanhos_Larguras, centers = 3)
# monstrar o resultado
resultado
# Unindo os resultados com os nomes das espécies
table(datasetIris$Especies, resultado$cluster)
# Plotar o resultado, levando em consideração os atributos da Sépala
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster)
points(resultado$centers[,c("Sepala.Tamanho", "Sepala.Largura")], col=1:3, pch="o", cex=3)
points(resultado$centers[,c("Sepala.Tamanho", "Sepala.Largura")], col=1:3, pch=20, cex=3)
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster, pch=20)
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster, pch=18)
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster, pch=20)
## Exemplo, Aprendizado de Máquina não supervisinado
# Obtendo o dataset com espécies da flor Iris
datasetIris <- iris
names(datasetIris) <- c("Sepala.Tamanho", "Sepala.Largura", "Petala.Tamanho", "Petala.Largura", "Especies")
# Vamos verificar como esta a distribuição deste dataset
summary(datasetIris)
# Pegando apenas as colunas com os tamanhos e larguras (da Sépala e da Pétala)
tamanhos_Larguras = datasetIris[,-5]
# Executar o algoritmo k-means com o dataset filtrado acima (x) e pedindo para encontrar 3 grupos (centers).
resultado <- kmeans(x = tamanhos_Larguras, centers = 3)
# monstrar o resultado
resultado
# Unindo os resultados com os nomes das espécies
table(datasetIris$Especies, resultado$cluster)
# Plotar o resultado, levando em consideração os atributos da Sépala
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster)
points(resultado$centers[,c("Sepala.Tamanho", "Sepala.Largura")], col=1:3, pch="o", cex=3)
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster, pch=20)
points(resultado$centers[,c("Sepala.Tamanho", "Sepala.Largura")], col=1:3, pch="o", cex=3)
points(resultado$centers, col=1:3, pch="o", cex=3)
plot(tamanhos_Larguras, col=resultado$cluster, pch=20)
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Petala.Tamanho")], col=resultado$cluster, pch=20)
points(resultado$centers[,c("Sepala.Tamanho", "Petala.Tamanho")], col=1:3, pch="o", cex=3)
## Exemplo, Aprendizado de Máquina não supervisinado
# Obtendo o dataset com espécies da flor Iris
datasetIris <- iris
names(datasetIris) <- c("Sepala.Tamanho", "Sepala.Largura", "Petala.Tamanho", "Petala.Largura", "Especies")
# Vamos verificar como esta a distribuição deste dataset
summary(datasetIris)
# Pegando apenas as colunas com os tamanhos e larguras (da Sépala e da Pétala)
tamanhos_Larguras = datasetIris[,-5]
# Executar o algoritmo k-means com o dataset filtrado acima (x) e pedindo para encontrar 3 grupos (centers).
resultado <- kmeans(x = tamanhos_Larguras, centers = 3)
# monstrar o resultado
resultado
# Unindo os resultados com os nomes das espécies
table(datasetIris$Especies, resultado$cluster)
# Plotar o resultado, levando em consideração os atributos da Sépala
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster)
points(resultado$centers[,c("Sepala.Tamanho", "Sepala.Largura")], col=1:3, pch="o", cex=3)
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster, pch=14)
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster, pch=10)
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster, pch=9)
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster, pch=5)
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster, pch=6)
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster, pch=2)
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster, pch=1)
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster, pch=20)
plot(tamanhos_Larguras[c("Sepala.Tamanho", "Sepala.Largura")], col=resultado$cluster, pch=18)
points(resultado$centers[,c("Sepala.Tamanho", "Sepala.Largura")], col=1:3, pch="o", cex=3)
??dbscan
if(!require(dbscan)) install.packages("dbscan")
library("dbscan")
data("DS3")
plot(DS3, pch=20, cex=0.25)
cl2 <- hdbscan(DS3, minPts = 25)
plot(DS3, col=cl2$cluster+1,
pch=ifelse(cl2$cluster == 0, 8, 1), # Mark noise as star
cex=ifelse(cl2$cluster == 0, 0.5, 0.75), # Decrease size of noise
xlab=NA, ylab=NA)
colors <- sapply(1:length(cl2$cluster),
function(i) adjustcolor(palette()[(cl2$cluster+1)[i]], alpha.f = cl2$membership_prob[i]))
points(DS3, col=colors, pch=20)
db <- dbscan(DS3, minPts = 25, eps = 0.25)
plot(DS3, col=db$cluster+1,
pch=ifelse(db$cluster == 0, 8, 1), # Mark noise as star
cex=ifelse(db$cluster == 0, 0.5, 0.75), # Decrease size of noise
xlab=NA, ylab=NA)
colors <- sapply(1:length(db$cluster),
function(i) adjustcolor(palette()[(db$cluster+1)[i]], alpha.f = db$membership_prob[i]))
points(DS3, col=colors, pch=20)
plot(cl2, scale = 3, gradient = c("purple", "orange", "red"), show_flat = T)
plot(cl2, scale = 3, show_flat = T)
plot(cl2, scale = 5, show_flat = T)
plot(cl2, scale = 5, show_flat = T, xlab = "Agrupamentos")
plot(cl2, scale = 5, show_flat = T, xlab = "Agrupamentos", ylab="Valor de Epilson")
plot(cl2, scale = 5, gradient = c("yellow", "orange", "red"), show_flat = T, xlab = "Agrupamentos", )
plot(cl2, scale = 5, gradient = c("blue", "orange", "red"), show_flat = T, xlab = "Agrupamentos", )
plot(cl2, scale = 5, show_flat = T, xlab = "Agrupamentos", ylab="Valor de Epilson")
plot(cl2, scale = 5, show_flat = T, xlab = "Agrupamentos")
colorRampPalette(c("red","yellow","springgreen","royalblue"))
colfunc<-colorRampPalette(c("red","yellow","springgreen","royalblue"))
plot(cl2, scale = 5, gradient = colfunc, show_flat = T, xlab = "Agrupamentos", )
plot(cl2, scale = 5, gradient = c("#00ffbf", "#00bfff", "#0000ff"), show_flat = T, xlab = "Agrupamentos", )
plot(cl2, scale = 5, gradient = c("#e6f2ff", "#0080ff", "#004080"), show_flat = T, xlab = "Agrupamentos", )
plot(cl2, scale = 5, gradient = c("#e6f2ff", "#0080ff", "#004080", "yellow"), show_flat = T, xlab = "Agrupamentos", )
data("moon")
# ============================================================
# EVALUATION - DBScan
# ============================================================
# Realiza a clusterização das característas obtidas na Mineração de códigos no GitHub
# ===========
setwd("G:/Mestrado/Meus experimentos/BugAID-Modificado/evaluation/codeR")
# ===========
# Leitura de CSV
#dataset.charles <- read.csv(file="datasets/posdeposito/dataset_bugid_with_header_Charles_FINAL.csv", header=TRUE, sep=",")
#dataset.hanam <- read.csv(file="datasets/posdeposito/dataset_bugid_with_header_Hanam_FINAL.csv", header=TRUE, sep=",")
dataset.charles <- read.csv(file="datasets/posdeposito/dataset_bugid_with_header_Charles_FINAL_Equals.csv", header=TRUE, sep=",")
dataset.hanam <- read.csv(file="datasets/posdeposito/dataset_bugid_with_header_Hanam_FINAL_Equals.csv", header=TRUE, sep=",")
View(dataset.charles)
